---
title: 3.线性系统和特征值
zhihu-url: https://zhuanlan.zhihu.com/p/561425309
---
关于新的这套重编，我建了一个qq群，有愿意讨论的欢迎进群：群号750758367



实际上线代的很多定理和线性系统有关。什么叫线性系统呢，我们可以看这个方程
$$
\left[\begin{array}{c}
j_{k+1} \\
s_{k+1} \\
a_{k+1}
\end{array}\right]=\left[\begin{array}{rrr}
4 & -1 & 6 \\
2 & 1 & 6 \\
2 & -1 & 8
\end{array}\right]\left[\begin{array}{c}
j_k \\
s_k \\
a_k
\end{array}\right]
$$
我们可以发现，随着k的变动，$\left[\begin{array}{c} j_k \\ s_k \\ a_k \end{array}\right]$也是依旧在变动的，我们想要得到对于某个k，这个向量的值是多少

在这里我我并不想向别的书一样，去定义向量空间的内容，相关的内容我会放在后面的章节，在这里你只需要记住，在几何直观中，向量空间便是一个平面，一个空间，一条线，因此

在这里你只要记住$R^n$是一个向量空间即可

我们简单的定义一下$R^n$中的向量

> v=$(x_1,\dots x_n)$是一个向量，而$R^n$={$(x_1,\dots x_n),x_i\in R$}其中n被称为v的维度，也是$R^n$的维度

比如v=(1,2)是一个向量，而$R^2$就是一个平面，v就是这个平面上的一个点

知道这些目前就已经够用了，在后续章节中再讨论向量空间的更高阶的用法

我们注意到实际上上面的式子的可以被写为$x_{k+1}=Ax_k$

而同时我们又可以把矩阵当成是一个函数，也就是$x_{k+1}=T(x_k)$

但这种函数又比较特殊，我们把他称为线性函数，关于线性函数的定义，我在这里也不细说，后续章节会讲

另外线性函数还有一个比较特殊的性质，那就是$range T=\{Tv|v \in U\},null T={v|Tv=0,v\in U}$也是向量空间（这个可以通过动画表现出来）

这里的U是向量空间，你也可以理解为就是$R^n$

那回到上面的线性系统，我们怎么去算对于某个k下的$x_k$呢

你可能会想多个矩阵相乘，但这明显很麻烦（你要至少计算$n^3$次）有没有更快的方法进行计算呢

此时就有人发现，假设初始值是$x_1=$(1,2,0)此时相乘后会得到$x_2$=(2,4,0)，再继续相乘$x_3=(4,6,0)$..

你会发现，实际上$x_k=(2^{k-1},2^k,0)$挺神奇的，这就是我们要讲的特征值和特征向量。

多提一嘴，最早发现特征值的人，实际上是在研究一个物体的拉伸和旋转（拉伸和旋转也可以本身也便可理解为线性映射），当时他们就遇到说需要将方程式进行多次的相乘的情况，而这时候有人发现，貌似对于线性映射而言，存在一个轴，这个轴上的东西，在进行线性映射后，他的方向是不会变化的。这个轴上的向量也被称为特征向量，而映射后轴上拉伸倍数也被称为“特诊值”

接下来我们给他一个定义

> 对于矩阵A而言，如果存在一个非零向量x和一个数$\lambda$使得$Ax=\lambda x$成立，此时$\lambda$被称为特诊值，而x被称为是特征向量

此时要怎么求解这个特征向量呢

显然的，方程$Ax=\lambda x$可以被化简为$(A-\lambda I)x=0$

显然的，我们知道这个方程是有解的，而这个方程不能有唯一解（唯一解就是零向量），因此只能是无穷多解，此时我们知道系数矩阵$A-\lambda I$要满足$det (A-\lambda I)=0$即可

现在我们来看这个矩阵
$$
A=\left[\begin{array}{rrr}
5 & -1 & -1 \\
3 & 1 & -1 \\
4 & -2 & 1
\end{array}\right]
$$
我们计算他的特征值
$$
A-\lambda I=\left[\begin{array}{rrr}
5-\lambda & -1 & 1 \\
3 & 1-\lambda & -1 \\
4 & -2 & 1-\lambda
\end{array}\right]
$$
$det(A-\lambda I)=(3-\lambda)(2-\lambda)^2$

当$\lambda =2$的时候
$$
(A-\lambda I)x=\left[\begin{array}{rrr}
3 & -1 & -1 \\
3 & -1 & -1 \\
4 & -2 & -1
\end{array}\right]
\left[\begin{array}{rrr}
a \\
b \\
c
\end{array}\right]
$$
但这时候我们会发现矩阵可以被高斯消元为
$$
\left[\begin{array}{rrr}
3 & -1 & -1 \\
0 & 0 & 0 \\
1 & -1 & 0
\end{array}\right]
$$
换句话说，这里只需要一个知道一个未知数就可以知道剩下的未知数的解（后面我们会提到，这意味着解空间的维度为一）

在这道题目中，所有可能的解（或者叫做解空间），可以被表示为
$$
a\left[\begin{array}{rrr}
1 \\
1 \\
2
\end{array}\right]
$$
在上面的例子中，我们用行列式算出来的多项式中，$\lambda$的次数被称为“代数重数”

而下面未知数的解空间维度（或者说只要知道几个未知数就可以知道剩下未知数的值）的，被称为“几何重数”

而且从上面的例子可以看出来，代数重数和几何重数并不一定相等，至于为什么不等，以及代数重数的意义，在后面的章节中我们会提到，大家这里只要记住这个概念而已

特征值的应用实际上是特别广泛的，特别是微分方程领域，但篇幅有限，我在这里不进行多讲

另外再到这里埋下一个小伏笔，如果初始值是
$$
\left[\begin{array}{rrr}
1 \\
1 \\
3
\end{array}\right]
$$
你会发现这时候特诊值就没有用了。未来我们会引入广义特征向量和特诊值，完善线性系统的求解
